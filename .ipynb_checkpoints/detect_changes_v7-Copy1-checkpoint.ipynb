{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json,shutil\n",
    "import requests, jinja2\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime\n",
    "\n",
    "#globals (via a config later on)\n",
    "git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "\n",
    "\"\"\"\n",
    "sdk_url = 'https://api.github.com/repos/Azure/azure-sdk-for-python/'\n",
    "assumed_current_date = '2017-04-01' #all packages without build.json are assued to be current as of  04-01\n",
    "sdk_raw_url = 'https://raw.githubusercontent.com/Azure/azure-sdk-for-python/master/' \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('config/api2sdk2nuget.json', 'r') as f:\n",
    "    map_object = json.load(f)\n",
    "    \n",
    "sdk_map = map_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'swagger_to_sdk_config_file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f0ec618aee0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#x = request_helper(git_url + 'contents/' + 'random' )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mswagger_to_sdk_config_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'swagger_to_sdk_config_file_name' is not defined"
     ]
    }
   ],
   "source": [
    "#x = request_helper(git_url + 'contents/' + 'random' )\n",
    "swagger_to_sdk_config_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#existing_changes = get_existing_changes_v4()\n",
    "#get_changes_for_project('arm-devtestlabs', '2016-05-15', 'DTL.json' , '2017-04-26T22:48:42Z')\n",
    "#get_changes_for_project('arm-servicebus', '2015-08-01', 'servicebus.json' , '2017-04-01')\n",
    "sdk_url = 'https://api.github.com/repos/Azure/azure-sdk-for-python/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Project :devtestlabs\n",
      "arm-devtestlabs 2016-05-15 DTL.json 2017-04-26T22:48:42Z\n",
      "Process Project :servicebus\n",
      "arm-servicebus 2015-08-01 servicebus.json 2017-04-01\n",
      "Process Project :machinelearning\n",
      "arm-machinelearning 2016-05-01-preview webservices.json 2017-04-01\n",
      "    arm-machinelearning :has a new folder : 2017-01-01\n",
      "Process Project :documentdb\n",
      "arm-documentdb 2015-04-08 documentdb.json 2017-05-01T20:13:42Z\n",
      "   No Nuget URL Map for azure api: arm-documentdb\n",
      "Process Project :redis\n",
      "arm-redis 2016-04-01 redis.json 2017-04-18T20:13:42Z\n",
      "    arm-redis :has a new folder : 2017-02-01\n",
      "Process Project :datalake.analytics.account\n",
      "arm-datalake-analytics/account 2016-11-01 account.json 2017-04-18T20:13:42Z\n",
      "Process Project :web\n",
      "arm-web Composite compositeWebAppClient.json 2017-04-26T22:48:42Z\n",
      "   COMPOSITE_SWAGGERarm-web/compositeWebAppClient.json\n",
      "Process Project :logic\n",
      "arm-logic 2016-06-01 logic.json 2017-04-18T20:13:42Z\n",
      "Process Project :keyvault.mgmt\n",
      "arm-keyvault 2015-06-01 keyvault.json 2017-04-18T20:13:42Z\n",
      "    arm-keyvault :has a new folder : 2016-10-01\n",
      "Process Project :servermanager\n",
      "arm-servermanagement 2016-07-01-preview servermanagement.json 2017-04-01\n",
      "Process Project :rdbms.mysql\n",
      "arm-rdbms 2017-04-30-preview Rdms.MySQL.json 2017-04-01\n",
      "    errors in project -->rdbms.mysql\n",
      "Project arm-rdbms not found. Probably private\n",
      "Process Project :rdbms.postgres\n",
      "arm-rdbms 2017-04-30-preview Rdms.PostgreSQL.json 2017-04-01\n",
      "    errors in project -->rdbms.postgres\n",
      "Project arm-rdbms not found. Probably private\n",
      "Process Project :scheduler\n",
      "arm-scheduler 2016-03-01 scheduler.json 2017-04-18T20:13:42Z\n",
      "Process Project :resources.subscriptions.2016-06-01\n",
      "arm-resources/subscriptions 2016-06-01 subscriptions.json 2017-05-04T19:23:06Z\n",
      "Process Project :dns\n",
      "arm-dns 2016-04-01 dns.json 2017-04-18T20:13:42Z\n",
      "Process Project :datalake.analytics.job\n",
      "arm-datalake-analytics/job 2016-11-01 job.json 2017-04-18T20:13:42Z\n",
      "Process Project :iothub\n",
      "arm-iothub 2016-02-03 iothub.json 2017-04-21T17:45:43Z\n",
      "    arm-iothub :has a new folder : 2017-01-19\n",
      "Process Project :search\n",
      "arm-search 2015-08-19 search.json 2017-04-01\n",
      "Process Project :resources.links.2016-09-01\n",
      "arm-resources/links 2016-09-01 links.json 2017-05-04T19:23:06Z\n",
      "Process Project :keyvault.data\n",
      "keyvault 2016-10-01 keyvault.json 2017-04-18T20:13:42Z\n",
      "Process Project :servicefabric\n",
      "servicefabric 5.6.130 servicefabric.json 2017-04-01\n",
      "    servicefabric :has a new folder : 2016-01-28\n",
      "    No Nuget URL Map for azure api: servicefabric\n",
      "Process Project :commerce\n",
      "arm-commerce 2015-06-01-preview commerce.json 2017-04-01\n",
      "Process Project :cdn\n",
      "arm-cdn 2016-10-02 cdn.json 2017-04-01\n",
      "Process Project :billing\n",
      "arm-billing 2017-04-24-preview billing.json 2017-04-01\n",
      "    No Nuget URL Map for azure api: arm-billing\n",
      "Process Project :cognitiveservices\n",
      "arm-cognitiveservices 2017-04-18 cognitiveservices.json 2017-04-26T22:48:42Z\n",
      "Process Project :monitor.mgmt\n",
      "arm-monitor Composite compositeMonitorManagementClient.json 2017-04-26T22:48:42Z\n",
      "   COMPOSITE_SWAGGERarm-monitor/compositeMonitorManagementClient.json\n",
      "Process Project :media\n",
      "arm-mediaservices 2015-10-01 media.json 2017-04-01\n",
      "Process Project :authorization\n",
      "arm-authorization 2015-07-01 authorization.json 2017-04-28T21:59:35Z\n",
      "Process Project :graphrbac\n",
      "arm-graphrbac Composite compositeGraphRbacManagementClient.json 2017-04-18T20:13:42Z\n",
      "   COMPOSITE_SWAGGERarm-graphrbac/compositeGraphRbacManagementClient.json\n",
      "Process Project :resources.features.2015-12-01\n",
      "arm-resources/features 2015-12-01 features.json 2017-05-04T19:23:06Z\n",
      "Process Project :monitor.data\n",
      "monitor Composite compositeMonitorClient.json 2017-04-18T20:13:42Z\n",
      "   COMPOSITE_SWAGGERmonitor/compositeMonitorClient.json\n",
      "Process Project :containerregistry\n",
      "arm-containerregistry 2017-03-01 containerregistry.json 2017-04-18T20:13:42Z\n",
      "    arm-containerregistry :has a new folder : 2017-06-01-preview\n",
      "Process Project :resources.managedapplications.2016-09-01-preview\n",
      "arm-resources/managedapplications 2016-09-01-preview managedapplications.json 2017-05-04T19:23:06Z\n",
      "    No Nuget URL Map for azure api: arm-resources/managedapplications\n",
      "Process Project :notificationhubs\n",
      "arm-notificationhubs 2016-03-01 notificationhubs.json 2017-04-01\n",
      "    arm-notificationhubs :has a new folder : 2017-04-01\n",
      "Process Project :datalake.analytics.catalog\n",
      "arm-datalake-analytics/catalog 2016-11-01 catalog.json 2017-04-18T20:13:42Z\n",
      "Process Project :batch\n",
      "batch 2017-05-01.5.0 BatchService.json 2017-05-18T22:46:36Z\n",
      "   No Nuget URL Map for azure api: batch\n",
      "Process Project :eventhub\n",
      "arm-eventhub 2015-08-01 EventHub.json 2017-04-01\n",
      "Process Project :batch.management\n",
      "arm-batch 2017-05-01 BatchManagement.json 2017-05-10T15:04:08Z\n",
      "Process Project :sql\n",
      "arm-sql Composite compositeSql.json 2017-04-28T21:59:35Z\n",
      "   COMPOSITE_SWAGGERarm-sql/compositeSql.json\n",
      "Process Project :consumption\n",
      "arm-consumption 2017-04-24-preview consumption.json 2017-04-01\n",
      "    No Nuget URL Map for azure api: arm-consumption\n",
      "Process Project :powerbiembedded\n",
      "arm-powerbiembedded 2016-01-29 powerbiembedded.json 2017-04-01\n",
      "Process Project :datalake.store.account\n",
      "arm-datalake-store/account 2016-11-01 account.json 2017-04-18T20:13:42Z\n",
      "Process Project :trafficmanager\n",
      "arm-trafficmanager 2017-03-01 trafficmanager.json 2017-04-18T20:13:42Z\n",
      "    arm-trafficmanager :has a new folder : 2017-05-01\n",
      "Swagger: arm-network/compositeNetworkClient_2016_09_01.json Not found\n",
      "Swagger: arm-network/compositeNetworkClient_2016_12_01.json Not found\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "Swagger: arm-compute/compositeComputeClient_2016_04_30_preview.json Not found\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Done finding existing changes\n"
     ]
    }
   ],
   "source": [
    "raw_url = 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/' \n",
    "sdk_raw_url = 'https://raw.githubusercontent.com/Azure/azure-sdk-for-python/master/'\n",
    "swagger_to_sdk_config_file_name = 'swagger_to_sdk_config.json'\n",
    "assumed_current_date = '2017-04-01'\n",
    "sdk_url = 'https://api.github.com/repos/Azure/azure-sdk-for-python/'\n",
    "get_ch_4(swagger_to_sdk_config_file_name, sdk_raw_url, assumed_current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ch_4(swagger_to_sdk_file, sdk_raw_url, assumed_current_date): \n",
    "    \n",
    "    existing_changes ={}\n",
    "    existing_changes['errors'] = {}\n",
    "\n",
    "    #get main swagger_to_sdk_config file \n",
    "\n",
    "    swagger_to_sdk = request_helper(sdk_raw_url + swagger_to_sdk_file )\n",
    "\n",
    "    #get normal sdks (points to SINGLE API SPEC on AZURE-API-SPEC), and multiple sdks (POINTS to SAME AZURE-API-SPEC on github)\n",
    "    s_to_sdk_projects = sorted([s for s in swagger_to_sdk['projects'] ])\n",
    "\n",
    "    multi_sdk = {} \n",
    "\n",
    "    normal_sdk = []\n",
    "\n",
    "    d ={}\n",
    "\n",
    "    for i in range(len(s_to_sdk_projects)):\n",
    "        azure_api_x = parse_swagger_to_sdk_config(swagger_to_sdk['projects'][s_to_sdk_projects[i]])[0]\n",
    "        if not d.get(azure_api_x):\n",
    "            d[azure_api_x] = []\n",
    "            d[azure_api_x].append(s_to_sdk_projects[i])\n",
    "        else:\n",
    "             d[azure_api_x].append(s_to_sdk_projects[i])\n",
    "\n",
    "    for a in d:\n",
    "        if len(d.get(a)) >1 and 'rdbms' not in a:\n",
    "            multi_sdk[a] = d[a]     \n",
    "        else:\n",
    "            for sdk in d.get(a):\n",
    "                normal_sdk.append(sdk)\n",
    "\n",
    "    #process normal sdk projects first (i.e, one that points to SINGLE API SPEC on AZURE-API-SPECs)\n",
    "\n",
    "    for proj in normal_sdk:\n",
    "\n",
    "        #if 'devtestlabs' in proj:\n",
    "\n",
    "        print ('Process Project :' + proj )\n",
    "\n",
    "        #(u'arm-commerce', u'2015-06-01-preview', u'commerce.json'), (u'arm-network', 'Composite', u'compositeNetworkClient_2015_06_15.json')\n",
    "\n",
    "        azure_api_name, c_composite, c_swagger, sdk, namespace = parse_swagger_to_sdk_config(swagger_to_sdk['projects'][proj])\n",
    "\n",
    "        current_swagger_path = swagger_to_sdk['projects'][proj]['swagger']\n",
    "\n",
    "        #right now there is no build.json info included in swagger_to_sdk_config.json, so try to find build.json for each 'sdk'\n",
    "        #note c_swagger is \"short form -> i.e xyz.json\" , swagger_path is full path including the folder. \n",
    "\n",
    "        sdk_recent_build = get_python_sdk_build_info(sdk)\n",
    "\n",
    "        if not sdk_recent_build:\n",
    "            c_recent_date = assumed_current_date #assume it's current as of April 15th. \n",
    "            c_version = swagger_to_sdk['projects'][proj]['autorest_options'].get(\"PackageVersion\", \"0.00\") #assume current version == package version\n",
    "\n",
    "        else:\n",
    "            c_recent_date = sdk_recent_build['date']\n",
    "            c_version = sdk_recent_build['version']\n",
    "\n",
    "        meta = {'azure_api_name' : azure_api_name, 'composite_or_recent_folder' : c_composite, \n",
    "                               'current_swagger': current_swagger_path , 'recent_build_date': c_recent_date, \n",
    "                               'current_version':c_version, 'sdk_proj_name' : proj}\n",
    "\n",
    "        print azure_api_name, c_composite, c_swagger, c_recent_date\n",
    "\n",
    "        get_changes = get_changes_for_project(azure_api_name, c_composite, current_swagger_path , c_recent_date)\n",
    "        \n",
    "        #print get_changes\n",
    "\n",
    "        project_changes = {}\n",
    "\n",
    "        project_changes['meta'] = meta\n",
    "\n",
    "        if get_changes.get('changes'):\n",
    "            project_changes['changes'] = get_changes.get('changes')\n",
    "\n",
    "        if get_changes.get('errors'):\n",
    "            print ('    errors in project -->') + proj \n",
    "            print get_changes.get('errors')\n",
    "            if any(get_changes.get('errors')):\n",
    "                project_changes['errors'] =  get_changes.get('errors')\n",
    "                existing_changes['errors'][proj] = project_changes['errors']\n",
    "\n",
    "\n",
    "        if get_changes.get('nuget_info'):\n",
    "            project_changes['nuget_info'] = get_changes.get('nuget_info')\n",
    "\n",
    "        if not existing_changes.get(sdk):\n",
    "            existing_changes[sdk] = project_changes\n",
    "\n",
    "        else: \n",
    "            if existing_changes[sdk].get('same_sdk'):\n",
    "                existing_changes[sdk]['same_sdk'][proj] = project_changes\n",
    "            else:\n",
    "                #get the very first one. \n",
    "                clip = existing_changes.pop(sdk, None)\n",
    "                existing_changes[sdk] ={}\n",
    "                existing_changes[sdk]['same_sdk'] = {}\n",
    "                #clip = existing_changes.get(sdk)\n",
    "                proj_name = clip['meta']['sdk_proj_name']\n",
    "                existing_changes[sdk]['same_sdk'][proj_name] = clip \n",
    "                existing_changes[sdk]['same_sdk'][proj] = project_changes\n",
    "\n",
    "\n",
    "    #process multi sdks\n",
    "\n",
    "    for m in multi_sdk:\n",
    "        multi_changes = get_changes_for_projects_multi(m, multi_sdk[m], swagger_to_sdk, assumed_current_date='2017-04-01')\n",
    "        sdk= multi_changes['sdk']\n",
    "        top_changes = multi_changes['changes']\n",
    "        multiple_projects = multi_changes['multiple_projects']\n",
    "\n",
    "        if not existing_changes.get(sdk):\n",
    "            existing_changes[sdk] = {'changes': top_changes, 'multiple_projects' : multiple_projects}\n",
    "\n",
    "    #consolidate errors for multi projects, find out max swagger behind when therea re multiple swagger updates\n",
    "\n",
    "    for e in existing_changes:\n",
    "        if existing_changes[e].get('multiple_projects'):\n",
    "            proj = existing_changes[e].get('multiple_projects')\n",
    "            for p in proj:\n",
    "                if proj[p].get('errors'):\n",
    "                    print proj[p].get('errors')\n",
    "                    existing_changes['errors'][p] = proj[p].get('errors')\n",
    "\n",
    "        if existing_changes[e].get('changes'):\n",
    "            if existing_changes[e]['changes'].get('ind_changes'):\n",
    "                ind_change = existing_changes[e]['changes'].get('ind_changes')\n",
    "                max_behind = 1\n",
    "                for k,v in ind_change.items():\n",
    "                    print v['swagger_behind']\n",
    "                    if v['swagger_behind'] > max_behind:\n",
    "                        max_behind = v['swagger_behind'] \n",
    "\n",
    "                existing_changes[e]['changes']['max_behind'] = max_behind\n",
    "\n",
    "\n",
    "    print(\"Done finding existing changes\")\n",
    "    #return existing_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets write the change output to file. \n",
    "with open('changes/test_existing_may22_b.json', 'w') as f:\n",
    "    json.dump(existing_changes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for e in existing_changes:\n",
    "    if existing_changes[e].get('multiple_projects'):\n",
    "        proj = existing_changes[e].get('multiple_projects')\n",
    "        for p in proj:\n",
    "            if proj[p].get('errors'):\n",
    "                print proj[p].get('errors')\n",
    "                existing_changes['errors'][p] = proj[p].get('errors')\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get new projects \n",
    "\n",
    "with open('changes/archived_2017_05_08.json', 'r') as f:\n",
    "    old_data = json.load(f)\n",
    "    \n",
    "new_projects = old_data['new_projects']\n",
    "new_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CREATE REPORT actual function to run everytime. \n",
    "#pungi\n",
    "with open('config/api2sdk2nuget.json', 'r') as f:\n",
    "    map_object = json.load(f)\n",
    "\n",
    "with open('config/fudge.json', 'r') as f:\n",
    "    build_file = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    "with open('changes/test_existing_may22.json', 'w') as f:\n",
    "    existing_projects = json.load(f) \n",
    "\"\"\"\n",
    "\n",
    "existing_projects = existing_changes\n",
    "print ('@@@@UPDATING FINDING CHANGES TO EXISTING PROJECTS .....')\n",
    "#existing_projects = get_existing_changes_v3(sdk_map, git_url=git_url, assumed_current_date=assumed_current_date)\n",
    "\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "report_time =  datetime.datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "env = Environment(loader=FileSystemLoader('templates'))\n",
    "template = env.get_template('jinja-template_v7c.html')\n",
    "\n",
    "seq = [k for k in sorted(existing_projects.iterkeys())]\n",
    "\n",
    "number_changes = sum([1 if existing_projects[c].get('changes') and not existing_projects[c].get('multiple')  else 0 for c in existing_projects ])\n",
    "errors=0\n",
    "\n",
    "if existing_projects.get('errors'):\n",
    "    errors = len( [e for e in existing_projects['errors'] ])\n",
    "\n",
    "print ('@@@@FOUND ....' + str(number_changes) + ' changes to existing projects')\n",
    "\n",
    "#update the missing PR numbers. \n",
    "\n",
    "try:\n",
    "    with open('config/sha2pr.json', 'r') as f:\n",
    "        sha2pr = json.load(f)\n",
    "except:\n",
    "    sha2pr = {}\n",
    "\n",
    "print ('@@@@UPDATING PRS .....')\n",
    "prs = update_remaining_PR_v2(existing_projects, sha2pr=sha2pr) #[[(u'azure-keyvault', u'ab6034c2ed4ae7347a5817242487706e5a49b73c', u'1195')]\n",
    "\n",
    "print(prs)\n",
    "\n",
    "for p in prs:\n",
    "    for p1 in p:\n",
    "        (proj, sha, pr)=  p1\n",
    "        sha2pr[sha] = pr \n",
    "        if existing_projects[proj].get('changes'):\n",
    "            existing_projects[proj]['changes']['pr_num'] = pr\n",
    "            \n",
    "print('@@@@WRITING UPDATES TO SHA2PR .....')\n",
    "\n",
    "print sha2pr\n",
    "\n",
    "with open('config/sha2pr.json', 'w')as f:\n",
    "    json.dump(sha2pr, f)\n",
    "\n",
    "#write the update dict object for fture use. \n",
    "\n",
    "\n",
    "print('@@@@CREATING OUTPUT FILE .....')\n",
    "\n",
    "\n",
    "output = template.render(new_projects=new_projects, existing_projects=existing_projects, \n",
    "                         recent_sha = '123',recent_date='abc', base=build_file, \n",
    "                         sdk_map= map_object, seq = seq, number_changes=number_changes, report_time=report_time, errors=errors)\n",
    "#print output\n",
    "#write to file. \n",
    "with open('test_report_may11.html', 'w') as f:\n",
    "    f.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in existing_projects:\n",
    "    if existing_projects[e].get('changes'):\n",
    "        if existing_projects[e]['changes'].get('ind_changes'):\n",
    "            ind_change = existing_projects[e]['changes'].get('ind_changes')\n",
    "            max_behind = 1\n",
    "            for k,v in ind_change.items():\n",
    "                print v['swagger_behind']\n",
    "                if v['swagger_behind'] > max_behind:\n",
    "                    max_behind = v['swagger_behind'] \n",
    "                    \n",
    "            \n",
    "            existing_projects[e]['changes']['max_behind'] = max_behind\n",
    "            \n",
    "            \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prs = update_remaining_PR_v2(existing_projects, sha2pr=sha2pr) #[[(u'azure-keyvault', u'ab6034c2ed4ae7347a5817242487706e5a49b73c', u'1195')]\n",
    "\n",
    "print(prs)\n",
    "\n",
    "for p in prs:\n",
    "    for p1 in p:\n",
    "        (proj, sha, pr)=  p1\n",
    "        sha2pr[sha] = pr \n",
    "        \n",
    "        \"\"\"\n",
    "        if existing_projects[proj].get('changes'):\n",
    "            existing_projects[proj]['changes']['pr_num'] = pr    \n",
    "        \"\"\"\n",
    "            \n",
    "print('@@@@WRITING UPDATES TO SHA2PR .....')\n",
    "\n",
    "print sha2pr\n",
    "\n",
    "with open('config/sha2pr.json', 'w')as f:\n",
    "    json.dump(sha2pr, f)\n",
    "\n",
    "#write the update dict object for fture use. \n",
    "\n",
    "\"\"\"\n",
    "print('@@@@CREATING OUTPUT FILE .....')\n",
    "\n",
    "\n",
    "output = template.render(new_projects=new_projects, existing_projects=existing_projects, \n",
    "                         recent_sha = '123',recent_date='abc', base=build_file, \n",
    "                         sdk_map= map_object, seq = seq, number_changes=number_changes, report_time=report_time, errors=errors)\n",
    "#print output\n",
    "#write to file. \n",
    "with open('test_report_may11.html', 'w') as f:\n",
    "    f.write(output)  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_remaining_PR_v2(existing_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [u'4779d58229fbe5cb94e8c6c40204af0515c07677', u'156cd442edf6badb940149878cecfba2d3198776', u'cf35632382557982d526792bbc78d3e50888ff7e', u'12b641f181711ec1e9a50f1dcfc7861721aa3242', u'68c601d4a1fcc45f81f6bb5d2160ade962012ddf', u'26837ac3ab19dcd537ceb5805a4cbbfce205cc1b', u'ba50eafc653f8d6340bb261fd0da81dc1929a3be']\n",
    "y = [u'azure-mgmt-servicebus', u'azure-mgmt-datalake-store', u'azure-mgmt-storage', u'azure.mgmt.datalake.analytics.account', u'azure-mgmt-documentdb', u'azure-mgmt-eventhub', u'azure-mgmt-consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    print x[i], y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_prs_in_range(x[0:7], y[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prs_in_range(shas, projects):\n",
    "\n",
    "    \"\"\"\n",
    "    Small helper function to return PR numbers given a 1) list of shas, and 2) corresponding project names. \n",
    "    returns a tuple of project, sha, and pr_number -->(u'azure-mgmt-servicebus', u'ab6034c2ed4ae7347a5817242487706e5a49b73c', u'1138')\n",
    "    \"\"\"\n",
    "\n",
    "    return_list =[]    \n",
    "    \n",
    "    for i in range(len(projects)):\n",
    "        r_com = shas[i]\n",
    "        proj = projects[i]\n",
    "        pr_num = get_pr_from_commits(r_com)\n",
    "        \n",
    "        \n",
    "        if pr_num:\n",
    "            if '#' in pr_num:\n",
    "                pr_num = pr_num[1:]\n",
    "\n",
    "            return_list.append((proj, r_com, pr_num))\n",
    "\n",
    "        else:\n",
    "            return_list.append((proj, r_com, 'No PR num found'))\n",
    "\n",
    "    return return_list\n",
    "\n",
    "def update_remaining_PR_v2(existing_projects, max_lookup =50, sha2pr=None):\n",
    "    \"\"\"\n",
    "    given a max number of PR nums to find (usually 9, as github limits 10 per min.) updates the missing PR #\n",
    "    saves the commit_sha --> PR num relations in a json file (sha2pr_history.json) in order to minimize look up. \n",
    "    waits for 90 seconds for every 9 look up. \n",
    "    max_lookup value is safeguard to stop after 50 look ups (about 600 seconds)\n",
    "    sha2pr is a dict of {'sha' : 'pr_num' } that can be updated and kept to minimize future look ups. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if not sha2pr:\n",
    "        sha2pr = {}\n",
    "    \n",
    "    for p in existing_projects:\n",
    "        if existing_projects[p].get('changes'):\n",
    "            if not existing_projects[p]['changes'].get('pr_num'):\n",
    "                existing_projects[p]['changes']['pr_num'] = 'n.a'\n",
    "            else:\n",
    "                pr = existing_projects[p]['changes']['pr_num']\n",
    "                if '#' in pr:\n",
    "                    #remove the '#' from PR num. \n",
    "                    pr = pr[1:]\n",
    "                \n",
    "    \n",
    "    missing_pr_shas =[]\n",
    "    missing_pr_projects =[]\n",
    "    \n",
    "\n",
    "    for p in existing_projects:\n",
    "       \n",
    "        if existing_projects[p].get('changes'):\n",
    "            if existing_projects[p]['changes'].get('commit_sha'):   \n",
    "                if not existing_projects[p]['changes'].get('pr_num') or existing_projects[p]['changes']['pr_num'] == 'not found':\n",
    "                    r_commit = existing_projects[p]['changes']['commit_sha'][0]\n",
    "                    \n",
    "                    #check if r_commit is already is in the file.        \n",
    "                    if sha2pr.get(r_commit):\n",
    "                        existing_projects[p]['changes']['pr_num'] = sha2pr[r_commit]\n",
    "                        \n",
    "                    else:\n",
    "                        missing_pr_shas.append(r_commit)\n",
    "                        missing_pr_projects.append(p)\n",
    "                        \n",
    "    print \"Number of missing PRS -->\" + str(len(missing_pr_shas))\n",
    "    \n",
    "    print (missing_pr_shas)\n",
    "    print (missing_pr_projects)\n",
    "    \n",
    "    prs =[]\n",
    "    remaining =0\n",
    "    max_time = 0\n",
    "    userange = len(missing_pr_projects)\n",
    "    \n",
    "    if len(missing_pr_projects) > 9:\n",
    "        userange =9\n",
    "        remaining = len(missing_pr_projects) - 9\n",
    "        max_time +=9\n",
    "        \n",
    "        \n",
    "    #update the first 9 projects. \n",
    "    start = 0\n",
    "    end = userange\n",
    "\n",
    "\n",
    "    prs.append(get_prs_in_range(missing_pr_shas[start:end], missing_pr_projects[start:end]))\n",
    "    \n",
    "\n",
    "\n",
    "    if not remaining ==0:\n",
    "        time.sleep(90) \n",
    "\n",
    "        while remaining > 0 and max_time < max_lookup:\n",
    "\n",
    "            if remaining > 9:\n",
    "                start = start + 9 \n",
    "                end = end + 9 \n",
    "                remaining = remaining - 9 \n",
    "                max_time +=0\n",
    "            else:\n",
    "                start = start +9\n",
    "                end = start + remaining \n",
    "                remaining = 0  \n",
    "\n",
    "            prs.append(get_prs_in_range(missing_pr_shas[start:end], missing_pr_projects[start:end]))\n",
    "\n",
    "            time.sleep(90) \n",
    "\n",
    "    return prs\n",
    "    \n",
    "\n",
    "def parse_swagger_to_sdk_config(project):\n",
    "#count the #  of slashes 1 ->, composite file. , 3 =>swagger file with datefolder. > 3 staggered/subprojects. \n",
    "#Use the fact that folder -=2015, 2016, 2017. ..starts with 20\n",
    "\n",
    "    sdk = project['output_dir'].split('/')[0]\n",
    "\n",
    "    namespace = project['autorest_options']['Namespace']\n",
    "\n",
    "    if not namespace:\n",
    "        namespace = ''\n",
    "\n",
    "    swagger_file_path = project['swagger']\n",
    "\n",
    "    if not swagger_file_path:\n",
    "        return None \n",
    "\n",
    "    if 'swagger' in swagger_file_path:\n",
    "        #not a composite\n",
    "        split_path = swagger_file_path.split('/swagger/')   \n",
    "        azure_api = '/'.join(split_path[0].split('/')[0:-1])\n",
    "        folder, swagger_name = split_path[0].split('/')[-1], split_path[-1]\n",
    "\n",
    "\n",
    "    else:\n",
    "        #is a composite file. \n",
    "        folder = 'Composite'\n",
    "        split_path = swagger_file_path.split('/')\n",
    "        azure_api, swagger_name = split_path[0], split_path[-1]\n",
    "\n",
    "    #print azure_api, folder, swagger_name\n",
    "\n",
    "\n",
    "    #print azure_api_spec_folder, date_folder, swagger_file\n",
    "    return (azure_api, folder, swagger_name, sdk, namespace)\n",
    "\n",
    "def get_pr_from_swagger_path(azure_api_swagger_path):\n",
    "\n",
    "    swagger_soup_url = 'https://github.com/Azure/azure-rest-api-specs/blob/master/' + azure_api_swagger_path\n",
    "    page = requests.get(swagger_soup_url)\n",
    "    if page.status_code == 200:\n",
    "        pagesoup = BeautifulSoup(page.content)\n",
    "        \n",
    "    #get_new_project_details(new_proj[0])\n",
    "    page_pull = pagesoup.find(\"div\", class_ =\"commit-tease\")\n",
    "    if page_pull:\n",
    "        issue = page_pull.find(\"a\", class_=\"issue-link\")\n",
    "        if issue:\n",
    "            return issue['href'].split('/')[-1]\n",
    "        else:\n",
    "            return 'not found'\n",
    "    return 'not found'\n",
    "\n",
    "#request_helper(raw_url + 'compositeComputeClient_2016_04_30_preview.json')\n",
    "def update_multiple_projects_4_web(existing_changes):\n",
    "    for p in existing_changes:\n",
    "        if existing_changes[p].get('multiple') and existing_changes[p].get('parent_sdk'):\n",
    "            parent = existing_changes[p]['parent_sdk']\n",
    "            child = p\n",
    "            if existing_changes.get(parent) and existing_changes[child].get('changes'):\n",
    "                \n",
    "                if not existing_changes[parent]['meta'].get('multiple_changes'):\n",
    "                    existing_changes[parent]['meta']['multiple_changes'] = 'Yes'\n",
    "                    \n",
    "                if not existing_changes[parent].get('changes'):\n",
    "                    existing_changes[parent]['changes'] = {'multiple_changes' : 'Yes'}\n",
    "                 \n",
    "                if not existing_changes[parent].get('multiple_projects'):\n",
    "                    existing_changes[parent]['multiple_projects'] = {}\n",
    "\n",
    "                if not existing_changes[parent]['multiple_projects'].get(child):\n",
    "                    existing_changes[parent]['multiple_projects'][child] = {} \n",
    "                    existing_changes[parent]['multiple_projects'][child]['changes'] = existing_changes[child]['changes']\n",
    "                else:\n",
    "                     existing_changes[parent]['multiple_projects'][child]['changes'] = existing_changes[child]['changes']\n",
    "                        \n",
    "        if existing_changes[p].get('changes'):\n",
    "            #composite project has ind_project with changes.\n",
    "            #max swagger-behind to be reported correctly. \n",
    "            if existing_changes[p]['changes'].get('ind_changes'):\n",
    "                max = existing_changes[p]['changes']['swagger_behind']\n",
    "                for k,v in existing_changes[p]['changes']['ind_changes'].items():\n",
    "                    if v['swagger_behind'] > max:\n",
    "                        max = v['swagger_behind']\n",
    "                existing_changes[p]['changes']['swagger_behind'] = max \n",
    "\n",
    "                        \n",
    "def request_helper(url, access_token=None):\n",
    "    \"\"\"\n",
    "    helper function/method to call API using request and return JSON encoded object. \n",
    "    if fails or gets 404, raises error. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not access_token:\n",
    "        access_token = '2dd078a2a012e23bed1ff39015ead3675bc9f1d0'\n",
    "        \n",
    "    r = requests.get(url, auth=('username', access_token))\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        return \n",
    "    \n",
    "    else:\n",
    "        return r.json()\n",
    "    \n",
    "\n",
    "def should_ignore(changed_file):\n",
    "    \"\"\"\n",
    "    helper function to ignore certain files on azure_api_spec\n",
    "    example: xyz.md, xyz.js, /test/ , /examples/ ....\n",
    "    \n",
    "    \"\"\"\n",
    "    if not changed_file.endswith('.json'):\n",
    "        return True\n",
    "    \n",
    "    if changed_file.startswith('test/'):\n",
    "        return True\n",
    "    \n",
    "    if '/examples/' in changed_file:\n",
    "        return True\n",
    "    \n",
    "    if '/' not in changed_file:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    return False\n",
    "\n",
    "#should_ignore('test/somethih')\n",
    "\n",
    "\n",
    "def get_key_folder_params(git_url, azure_folder_path):\n",
    "    \"\"\"\n",
    "    returns the composite status. if there is a .json file in root folder. this will be yes. \n",
    "    returns the most recent folder (2015-10-11 is more recent than 2014-10-09)\n",
    "    \"\"\"   \n",
    "    rcomposite = request_helper(git_url + 'contents/' + azure_folder_path )\n",
    "    most_recent_composite_status = 'No' \n",
    "    folders =[]\n",
    "    for r in rcomposite:\n",
    "        path = r['path']\n",
    "        folder = path.split(azure_folder_path +'/')[1]\n",
    "        if folder.startswith('20') or folder.startswith('/20'): \n",
    "            folders.append(folder)\n",
    "        if '.json' in path:\n",
    "            most_recent_composite_status = 'Yes'\n",
    "            \n",
    "    \n",
    "    return(most_recent_composite_status, sorted(folders))\n",
    "\n",
    "def get_key_folder_params_v2(git_url, azure_folder_path):\n",
    "    \"\"\"\n",
    "    Given an azure api spec folder (which is a package) name, returns some key parameters for that package. \n",
    "    1) composite status. if there is a .json file in root folder. this will be yes. \n",
    "    2) most recent sub folder (2015-10-11 is more recent than 2014-10-09)\n",
    "    3) gets the swagger file. ??\n",
    "    \"\"\"   \n",
    "    rcomposite = request_helper(git_url + 'contents/' + azure_folder_path )\n",
    "    most_recent_composite_status = 'No' \n",
    "    swagger = None\n",
    "    folders =[]\n",
    "    for r in rcomposite:\n",
    "        path = r['path']\n",
    "        folder = path.split(azure_folder_path +'/')[1]\n",
    "        if folder.startswith('20') or folder.startswith('/20'): \n",
    "            folders.append(folder)\n",
    "        \n",
    "        print 'folder is ==='\n",
    "        \n",
    "        print folders\n",
    "        \n",
    "        if '.json' in path:\n",
    "            most_recent_composite_status = 'Yes'\n",
    "            swagger=path\n",
    "            \n",
    "    #print 'swagger is ===' + swagger\n",
    "  \n",
    "    if not swagger and folders:\n",
    "        r_file = request_helper(git_url + 'contents/' + azure_folder_path + '/' + folders[-1] + '/swagger/')\n",
    "        \n",
    "        \"\"\"\n",
    "        print 'r_file is =='\n",
    "        print r_file\n",
    "        print 'folder is at ==='\n",
    "        print git_url + 'contents/' + azure_folder_path + '/' + folders[-1] + '/Swagger/'\n",
    "        \"\"\"\n",
    "        if not r_file:\n",
    "            #try capital Swagger\n",
    "            r_file2 = request_helper(git_url + 'contents/' + azure_folder_path + '/' + folders[-1] + '/Swagger/')\n",
    "            if not r_file2:\n",
    "                return ('No', ['not-found'], '')\n",
    "            else:\n",
    "                swagger =''\n",
    "                for r in r_file2:\n",
    "                    if r.get('path'):\n",
    "                        #u'arm-timeseriesinsights/2017-02-28-preview/Swagger/timeseriesinsights.json'\n",
    "                        swagger = r['path']\n",
    "                        \n",
    "        if r_file:\n",
    "            swagger = ''\n",
    "            for r in r_file:\n",
    "                if '.json' in r:\n",
    "                    swagger = r \n",
    "                    break;\n",
    "                    \n",
    "    return(most_recent_composite_status, sorted(folders), swagger)\n",
    "\n",
    "def get_recent_from_nuget(package, base_url=None):\n",
    "    \"\"\"\n",
    "    given a name of a C# package on Nuget ('Microsoft.Azure.Management.DataLake.Store'), \n",
    "    returns the most recent version and published date\n",
    "    \"\"\"\n",
    "    #print package\n",
    "    if not base_url:\n",
    "        base_url = \"https://www.nuget.org/packages/\"\n",
    "    \n",
    "    page_result = requests.get(base_url + package)\n",
    "    \n",
    "    if page_result.status_code == 200:\n",
    "        soup = BeautifulSoup(page_result.content)\n",
    "        recent = soup.find(\"tr\", class_= \"versionTableRow recommended\")\n",
    "        recent_date, recent_release = '',''\n",
    "        \n",
    "        if recent:\n",
    "\n",
    "                    recent_date = recent.find(\"span\")['title']\n",
    "                    recent_release = recent.find(\"a\", href=True)['href'].split('/')[-1]\n",
    "                    \n",
    "        else:\n",
    "            #get another set of tables. \n",
    "            recent = soup.findAll(\"tr\", class_= \"versionTableRow\")\n",
    "            #print recent\n",
    "            if recent:\n",
    "                recent_v = recent[0]\n",
    "                recent_date = recent_v.find(\"span\")['title']\n",
    "                recent_release = recent_v.find(\"a\", href=True)['href'].split('/')[-1]\n",
    "    \n",
    "    return (recent_date, recent_release)\n",
    "\n",
    "\n",
    "\n",
    "def get_oldest_date_v2(file_dates, recent=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    default -takes a list of dates, or a date, and returns the 'oldest' days and # of days old (i,e, 40 days ago)from today\n",
    "    if recent=True, will return the 'most' recent date. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    \n",
    "    if type(file_dates) is list:\n",
    "        sorted_dates = sorted(file_dates)\n",
    "        if not recent:\n",
    "            oldest_change = sorted_dates[0] #default sorting in ascending order. \n",
    "        else:\n",
    "            oldest_change = sorted_dates[-1]\n",
    "        \n",
    "    else:\n",
    "        oldest_change = file_dates\n",
    "    \n",
    "    a = datetime.strptime(datetime.now().strftime(\"%Y-%m-%d\"), date_format)\n",
    "    b = datetime.strptime(oldest_change.split('T')[0], date_format)\n",
    "\n",
    "    #print str(abs(a-b))\n",
    "    days = str(abs(a-b)).split(',')[0]\n",
    "\n",
    "    return (oldest_change, days)\n",
    "\n",
    "#get_oldest_date(file_dates)\n",
    "\n",
    "def get_recent_from_nuget_v2(package, base_url=None):\n",
    "    \"\"\"\n",
    "    given a name of a C# package on Nuget ('Microsoft.Azure.Management.DataLake.Store'), \n",
    "    returns the most recent version and published date\n",
    "    \"\"\"\n",
    "    #print package\n",
    "    if not base_url:\n",
    "        base_url = \"https://www.nuget.org/packages/\"\n",
    "    \n",
    "    try:\n",
    "        page_result = requests.get(base_url + package)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    d = { 'nuget_recent' : {}, 'nuget_stable' : {} }\n",
    "    \n",
    "    if page_result.status_code == 200:\n",
    "        soup = BeautifulSoup(page_result.content)\n",
    "        stable = soup.find(\"tr\", class_= \"versionTableRow recommended\")\n",
    "        recents = soup.findAll(\"tr\", class_= \"versionTableRow\")\n",
    "        recent_date, recent_release, stable_date, stable_release = '','', '', ''\n",
    "        recent_href, stable_href = '',''\n",
    "        \n",
    "        if stable:\n",
    "            stable_date = stable.find(\"span\")['title']\n",
    "            stable_days_ago = get_oldest_date_v2(stable_date)[1]\n",
    "            stable_href = stable.find(\"a\", href=True)['href']\n",
    "            stable_release = stable_href.split('/')[-1]\n",
    "            \n",
    "            d['nuget_stable'] = { 'stable_date': stable_date, 'stable_release' : stable_release, \n",
    "                           'stable_href': stable_href, 'stable_days_ago' : stable_days_ago } \n",
    "            \n",
    "                    \n",
    "        if recents:\n",
    "            recent = recents[0]\n",
    "            recent_date = recent.find(\"span\")['title']\n",
    "            recent_days_ago = get_oldest_date_v2(recent_date)[1]\n",
    "            recent_href = recent.find(\"a\", href=True)['href']\n",
    "            recent_release = recent_href.split('/')[-1]\n",
    "            \n",
    "            d['nuget_recent'] = { 'recent_date': recent_date, 'recent_release' : recent_release, \n",
    "               'recent_href': recent_href, 'recent_days_ago' : recent_days_ago }\n",
    "\n",
    "            \n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_key_folder_params_v3(git_url, azure_folder_path):\n",
    "    \"\"\"\n",
    "    Given an azure api spec folder (which is a package) name, returns some key parameters for that package. \n",
    "    1) composite status. if there is a .json file in root folder. this will be yes. \n",
    "    2) most recent sub folder (2015-10-11 is more recent than 2014-10-09)\n",
    "    3) gets the swagger file. ??\n",
    "    \"\"\"   \n",
    "    rcomposite = request_helper(git_url + 'contents/' + azure_folder_path )\n",
    "    \n",
    "    if not rcomposite:\n",
    "        return None\n",
    "    \n",
    "    most_recent_composite_status = 'No' \n",
    "    swagger = None\n",
    "    folders =[]\n",
    "    for r in rcomposite:\n",
    "        path = r['path']\n",
    "        folder = path.split(azure_folder_path +'/')[1]\n",
    "        if folder.startswith('20') or folder.startswith('/20'): \n",
    "            folders.append(folder)\n",
    "        if '.json' in path:\n",
    "            most_recent_composite_status = 'Yes'\n",
    "            swagger=path\n",
    "  \n",
    "    if not swagger and folders:\n",
    "        r_file = request_helper(git_url + 'contents/' + azure_folder_path + '/' + folders[-1] + '/swagger/')\n",
    "        swagger =''\n",
    "        for r in r_file:\n",
    "            #print r\n",
    "            if '.json' in r.get('name'):\n",
    "                swagger = r.get('path')\n",
    "        #swagger = r_file[0]['path']\n",
    "        \n",
    "            \n",
    "    return(most_recent_composite_status, sorted(folders), swagger)\n",
    "\n",
    "###GET build.json info from azure sdk page. #########\n",
    "\n",
    "def get_python_sdk_build_info(sdk_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    get the latest build.json from azure-sdk-python. \n",
    "    returns None if no build.json is found. \n",
    "    \"\"\"\n",
    "    \n",
    "    sdk_url = 'https://api.github.com/repos/Azure/azure-sdk-for-python/'\n",
    "    sdk_raw_url = 'https://raw.githubusercontent.com/Azure/azure-sdk-for-python/master/' \n",
    "\n",
    "    \n",
    "    key_sdk_data = get_key_folder_params_v3(sdk_url,  sdk_name)\n",
    "\n",
    "    if key_sdk_data and key_sdk_data[2] != None:\n",
    "        #print key_sdk_data\n",
    "        if 'build.json' in key_sdk_data[2]:\n",
    "        #get file info\n",
    "            build_file = request_helper(sdk_raw_url + key_sdk_data[2])\n",
    "\n",
    "            if build_file and build_file['date']:\n",
    "                build_info = { 'autorest' : build_file['autorest'], 'date' : build_file['date'], \n",
    "                              'version': build_file['version']}\n",
    "\n",
    "\n",
    "            #print (build_info)\n",
    "\n",
    "            return build_info \n",
    "    \n",
    "    else:\n",
    "        return \n",
    "    \n",
    "def compare_build_date(build_date, dates_list):\n",
    "        for i,d in enumerate(dates_list):\n",
    "            if d < build_date:\n",
    "                print (i, d)\n",
    "                return (i, d)\n",
    "                break;\n",
    "\n",
    "def get_azure_name_space_data(swagger_file_path):\n",
    "    #count the #  of slashes 1 ->, composite file. , 3 =>swagger file with datefolder. > 3 staggered/subprojects. \n",
    "    #Use the fact that folder -=2015, 2016, 2017. ..starts with 20\n",
    "    \n",
    "    split_path = swagger_file_path.split('/20')\n",
    "    \n",
    "    if len(split_path) > 1:\n",
    "        #not composite. \n",
    "        azure_api_spec_folder, date_folder, swagger_file  = split_path[0], '20'+ split_path[1].split('/')[0], split_path[1].split('/')[2]\n",
    "    \n",
    "    else:\n",
    "        azure_api_spec_folder, date_folder, swagger_file = split_path[0].split('/')[0], 'Composite',  split_path[0].split('/')[1]\n",
    "        \n",
    "    #print azure_api_spec_folder, date_folder, swagger_file\n",
    "    return (azure_api_spec_folder, date_folder, swagger_file)\n",
    "\n",
    "    \n",
    "def get_new_project_names_v2(azure_projects_in_sdk, git_url=None, ignore_list=None):\n",
    "    \"\"\"\n",
    "    given an existing list of project names (azure_projects_in_sdk,) in azure api spec namespaces\n",
    "    returns a list of projects that are not on azure api spec github but not in the input list. \n",
    "    \n",
    "    \"\"\"\n",
    "    if not ignore_list:\n",
    "        ignore_list = ['.github', '.gitignore', '.travis.yml', '.vscode', 'LICENSE' , 'README.md' , 'azure-rest-api-specs.sln', \n",
    "          'azure-rest-api-specs.njsproj', 'documentation', 'package.json', '.scripts' , 'scripts']\n",
    "\n",
    "    if not git_url:\n",
    "        git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "\n",
    "\n",
    "    api_folders = request_helper(git_url+'contents/')\n",
    "    #print(api_folders)\n",
    "    new_projects = []\n",
    "    for folder in api_folders:\n",
    "        f = folder['path'] #\n",
    "\n",
    "        if f not in ignore_list: \n",
    "            test =0 \n",
    "            for m in azure_projects_in_sdk:     \n",
    "                if f in m:\n",
    "                    test =1\n",
    "                    break; \n",
    "\n",
    "            if test ==0:\n",
    "                new_projects.append(f)\n",
    "                #print ('New project added:' + f)\n",
    "\n",
    "    #print(new_projects)\n",
    "    return new_projects\n",
    "\n",
    "def get_pr_from_commits(commit_sha, base_url=None, access_token=None):\n",
    "    \"\"\"\n",
    "    given a sha of commit on azure api spec, returns a PR# on github  (if there is one)\n",
    "    else, returns ' '\n",
    "    \"\"\"\n",
    "    #print package\n",
    "    #https://github.com/search?q=8461020530ea97978+repo%3AAzure%2Fazure-rest-api-specs&type=issues\n",
    "    \n",
    "    if not base_url:\n",
    "        base_url = \"https://github.com/search?q=\"\n",
    "        url_en = \"+repo%3AAzure%2Fazure-rest-api-specs&type=issues\"\n",
    "    \n",
    "    url = base_url+commit_sha+url_en\n",
    "    #print url\n",
    "    \n",
    "    if not access_token:\n",
    "        access_token = '2dd078a2a012e23bed1ff39015ead3675bc9f1d0'\n",
    "        \n",
    "    \n",
    "    page_result = requests.get(url, auth=('username', access_token))\n",
    "    \n",
    "    pr = ''\n",
    "    \n",
    "    print(page_result.status_code)\n",
    "    \n",
    "    if page_result.status_code == 200:\n",
    "        soup = BeautifulSoup(page_result.content)\n",
    "        try:\n",
    "            issue = soup.find(\"div\", class_= \"issue-list\")\n",
    "            pr = issue.find(\"span\", class_ =\"float-right\").contents[0]\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "    \n",
    "    return pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_changes_for_project(azure_api_name, c_composite, current_swagger_path , c_recent_date):\n",
    "    \n",
    "    \"\"\"\n",
    "    retruns the changes (if any there would be a key == 'changes' in the returned dictionary object) for a given project. Use this function when\n",
    "    there is 1-1 mapping between the SDK project and the azure API spec folder. (only 1 sdk project for a given AZURE API spec folder)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return_dict = {}\n",
    "    \n",
    "    return_dict['errors'] = {}\n",
    "\n",
    "    params = get_key_folder_params_v3(git_url,azure_api_name)\n",
    "\n",
    "    if not params:\n",
    "        return_dict['errors'] = 'Project ' + azure_api_name +' not found. Probably private' \n",
    "        #existing_changes['errors'][i] = 'Project ' + azure_api_name +' not found. Probably private'\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    else:\n",
    "        is_composite, folders, swagger = get_key_folder_params_v3(git_url,azure_api_name)\n",
    "\n",
    "        if c_composite =='Composite':\n",
    "            current_composite = 'Yes'\n",
    "            c_recent_folder = 'No'\n",
    "\n",
    "        else:\n",
    "            c_recent_folder = c_composite\n",
    "            current_composite = 'No'\n",
    "\n",
    "\n",
    "        #check changes in composite status. \n",
    "        if is_composite != current_composite:\n",
    "            #project composite status has changed. \n",
    "\n",
    "            changes = get_swagger_updates(swagger, git_url=git_url) \n",
    "            changes['use_swagger'] = swagger\n",
    "\n",
    "            if current_composite ==\"Yes\":\n",
    "                #is_composite is NO\n",
    "\n",
    "                print(azure_api_name + 'has changed to Composite to --> non composite')  \n",
    "\n",
    "                #get the details for this swagger file and update the details. \n",
    "\n",
    "                changes['change_type'] = \"CompositeStatus\"\n",
    "                changes['change_status'] = \"Moved to a non - composite swagger\"\n",
    "                return_dict['changes'] = changes\n",
    "\n",
    "\n",
    "            else:\n",
    "                #moved to a composite swagger. get all lower level swagger details if possible. \n",
    "\n",
    "                print('    ' + azure_api_name + ' :Moved to a composite swagger')\n",
    "                changes['change_type'] = \"CompositeStatus\"\n",
    "                changes['change_status'] = \"Moved to a composite swagger\"\n",
    "\n",
    "                return_dict['changes']= changes\n",
    "\n",
    "        #check if folder is the same \n",
    "        else:     \n",
    "            if is_composite =='No': \n",
    "                #there must be folders. \n",
    "                if len(folders) > 0: \n",
    "                    latest_folder = folders[-1]\n",
    "                    if c_recent_folder != latest_folder:\n",
    "\n",
    "                        print('    ' + azure_api_name + ' :has a new folder : ' + latest_folder)\n",
    "\n",
    "                        changes = get_swagger_updates(swagger, git_url=git_url)\n",
    "                        changes['use_swagger'] = swagger\n",
    "                        changes['change_type'] = \"Folder\"\n",
    "                        changes['new_folder'] = latest_folder\n",
    "                        return_dict['changes'] =changes\n",
    "\n",
    "                    else:\n",
    "                        #most proable scenario : check for swagger update. \n",
    "\n",
    "                        if current_swagger_path != swagger:\n",
    "                            print ('    ' + azure_api_name + ':swagger not found')\n",
    "                            #print(current_swagger_path, swagger)\n",
    "\n",
    "                        else:\n",
    "                            #get the current sha of from the recent date. \n",
    "\n",
    "                            changes = get_swagger_updates_v2(current_swagger_path, git_url=git_url, current_date=c_recent_date)\n",
    "\n",
    "                            if changes['swagger_behind'] >0:\n",
    "                                changes['change_type'] = \"SwaggerUpdate\"\n",
    "                                return_dict['changes'] = changes\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                print ('   COMPOSITE_SWAGGER' + current_swagger_path)\n",
    "\n",
    "                if not current_swagger_path:\n",
    "                        print (azure_api_name + '..swagger not found')\n",
    "                else:\n",
    "                    # check for the update in main composite file first \n",
    "                    changes_composite = get_swagger_updates_v2(current_swagger_path, git_url=git_url, current_date=c_recent_date)\n",
    "\n",
    "                    if changes_composite['swagger_behind'] >0:\n",
    "                        changes ={}\n",
    "                        changes['change_type'] = \"SwaggerUpdate\"\n",
    "                        return_dict['changes'] = changes\n",
    "\n",
    "                    # check for the update in main composite file first                 \n",
    "                    #get the full file and individual paths from the composite file. \n",
    "                    #raw_url = 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/' \n",
    "\n",
    "                    cfile= request_helper(raw_url + current_swagger_path)\n",
    "\n",
    "                    if not cfile:\n",
    "                        #current swagger file not found. \n",
    "                        return_dict['errors'][cfile] =  'swagger_file: ' + current_swagger_path +' not found' \n",
    "\n",
    "\n",
    "                    if cfile and cfile.get('documents'):\n",
    "\n",
    "                        for f in cfile.get('documents'):\n",
    "                            #get file history \n",
    "                            ind_swagger = azure_api_name + f[1:]\n",
    "                            #print ('IND_SWAGGER' + ind_swagger)\n",
    "                            \n",
    "                \n",
    "                            changes_ind_file = get_swagger_updates_v2(ind_swagger, git_url=git_url, current_date=c_recent_date)\n",
    "\n",
    "                            #catch any errors. \n",
    "\n",
    "                            if not changes_ind_file:\n",
    "                                return_dict['errors'] = ind_swagger + ' swagger_file : ' + ind_swagger +' not found'\n",
    "\n",
    "                            if changes_ind_file and changes_ind_file['swagger_behind'] >0:\n",
    "\n",
    "                                if return_dict.get('changes'):\n",
    "                                    if not return_dict['changes'].get('ind_changes'):\n",
    "                                        return_dict['changes']['ind_changes'] = {}\n",
    "                                        return_dict['changes']['ind_changes'][ind_swagger] = changes_ind_file\n",
    "                                    else:\n",
    "                                            return_dict['changes']['ind_changes'][ind_swagger] = changes_ind_file\n",
    "\n",
    "\n",
    "                            #d[ind_swagger] = {'sha' : file_data['commit_sha'], 'dates': file_data['file_dates']}\n",
    "\n",
    "        #print('CHANGES')\n",
    "\n",
    "        if not sdk_map.get(azure_api_name):\n",
    "            return_dict['nuget_info'] = {}\n",
    "            print('    No Nuget URL Map for azure api: ' + azure_api_name)\n",
    "\n",
    "        else:\n",
    "            nuget_package = sdk_map[azure_api_name].get('nuget_package')\n",
    "            if nuget_package:\n",
    "                return_dict['nuget_info'] = get_recent_from_nuget_v2(nuget_package) or 'Nuget info not found.'\n",
    "            else:\n",
    "                return_dict['nuget_info'] = {}\n",
    "                print('   No Nuget URL Map for azure api: ' + azure_api_name)\n",
    "                \n",
    "    return return_dict\n",
    "\n",
    "def get_changes_for_projects_multi(azure_api_name, sdk_project_list, swagger_to_sdk, assumed_current_date=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns changes for python sdk projects where each project points to the same SDK but different apis. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not assumed_current_date:\n",
    "        assumed_current_date = '2017-04-01'\n",
    "    \n",
    "    changes_m ={} #individual project changes with meta \n",
    "    changes_top = {} # top level changes, either composite status or folder. \n",
    "    \n",
    "    #azure_api_m = 'arm-resources/resources'\n",
    "    #mproj = d[azure_api_m] #[u'resources.resources.2016-02-01', u'resources.resources.2016-09-01', u'resources.resources.2017-05-10']\n",
    "    \n",
    "    azure_api_m = azure_api_name\n",
    "    mproj = sdk_project_list \n",
    "\n",
    "    folders = sorted([ f.split('.')[-1] for f in mproj ]) #[u'2016-02-01', u'2016-09-01', u'2017-05-10']\n",
    "\n",
    "    #get sdk to summarize under one sdk . \n",
    "    random_proj = mproj[0]\n",
    "    azure_api_name, c_composite, c_swagger, sdk, namespace = parse_swagger_to_sdk_config(swagger_to_sdk['projects'][random_proj])\n",
    "\n",
    "    #most recent folder \n",
    "    c_folder = folders[-1] \n",
    "    c_comp = 'No' #***VALDIATE: assumed there aren't any composite project in this type of case ****\n",
    "\n",
    "    is_composite, folders, swagger = get_key_folder_params_v3(git_url,azure_api_name)\n",
    "    latest_folder = folders[-1]\n",
    "\n",
    "    #check 1: if this azure api spec is now using composite \n",
    "    if is_composite != c_comp:\n",
    "        changes_top['changes'] = {}\n",
    "        changes_top['changes']['change_type'] = \"CompositeStatus\"\n",
    "        changes_top['changes']['change_status'] = \"Moved to a non - composite swagger\"\n",
    "        changes_top['changes']['use_swagger'] = swagger\n",
    "\n",
    "    #check 2: is there a folder more recent than this \n",
    "    if c_folder != latest_folder:\n",
    "        changes_top['changes'] = {}\n",
    "        changes_top['changes']['change_type'] = \"Folder\"\n",
    "        changes_top['changes']['new_folder']= latest_folder\n",
    "        changes_top['changes']['use_swagger'] = swagger\n",
    "\n",
    "    #check 3: for each proj in mproj a) if the json file and path is still valid? , b) is current ?\n",
    "    for proj in mproj:\n",
    "\n",
    "        current_swagger_m = swagger_to_sdk['projects'][proj]['swagger']\n",
    "\n",
    "        sdk_recent_build = get_python_sdk_build_info(sdk)\n",
    "\n",
    "        if not sdk_recent_build:\n",
    "            c_recent_date = assumed_current_date #assume it's current as of April 15th. \n",
    "            c_version = swagger_to_sdk['projects'][proj]['autorest_options'].get(\"PackageVersion\", \"0.00\") #assume current version == package version\n",
    "\n",
    "        else:\n",
    "            c_recent_date = sdk_recent_build['date']\n",
    "            c_version = sdk_recent_build['version']\n",
    "\n",
    "        meta = {'azure_api_name' : azure_api_name, 'composite_or_recent_folder' : c_composite, \n",
    "                           'current_swagger': current_swagger_m , 'recent_build_date': c_recent_date, \n",
    "                           'current_version':c_version, 'sdk_proj_name' : proj }\n",
    "\n",
    "        changes_m[proj] ={}\n",
    "        changes_m[proj]['meta'] = meta\n",
    "\n",
    "        if len(request_helper(git_url+'commits?path=' + current_swagger_m )) > 0:\n",
    "            swagger_changes = get_swagger_updates_v2(current_swagger_m, git_url=git_url, current_date= c_recent_date) \n",
    "   \n",
    "            if swagger_changes['swagger_behind'] > 0:\n",
    "\n",
    "                changes_m[proj]['changes'] = swagger_changes\n",
    "\n",
    "        else:\n",
    "\n",
    "            changes_m[proj]['errors'] = 'Swagger: ' + current_swagger_m + ' Not found'\n",
    "            \n",
    "            \n",
    "    return {'changes' : changes_top , 'multiple_projects': changes_m, 'sdk' : sdk }\n",
    "\n",
    "\n",
    "#swagger history \n",
    "def get_swagger_updates_v2(azure_api_swagger_path, git_url=None, current_date=None):\n",
    "    \"\"\"\n",
    "    return the updates to a swagger. \n",
    "    if a current_sha of a swagger is known, function returns the updates 'since' this current date\n",
    "    else, function returns the entire swagger history. \n",
    "\n",
    "    #current_sha = base_data['current_version']\n",
    "\n",
    "    \"\"\"\n",
    "    #object to return \n",
    "    \n",
    "    changes= {}\n",
    "    changes['file_dates'] = []\n",
    "    changes['commit_sha'] = []\n",
    "    changes['swagger_behind'] = 0\n",
    "   \n",
    "    #azure_api_swagger_path = 'keyvault/2016-10-01/swagger/keyvault.json'\n",
    "\n",
    "    if not current_date:\n",
    "        current_date = '2017-04-01'\n",
    "\n",
    "    swagger_history = request_helper(git_url+'commits?path=' + azure_api_swagger_path + \"&since=\" + current_date)\n",
    "\n",
    "    if not swagger_history:\n",
    "        #print(changes)\n",
    "        return changes\n",
    "\n",
    "    #else there are changes. \n",
    "\n",
    "    #print(swagger_history)\n",
    "\n",
    "    shas, dates  = [], [] \n",
    "    for s in swagger_history:\n",
    "        shas.append(s['sha'])\n",
    "        dates.append(s['commit']['committer']['date'])\n",
    "\n",
    "    if shas:\n",
    "        file_dates, commit_sha, swagger_behind = dates, shas, len(shas)\n",
    "\n",
    "    else:\n",
    "        #print(swagger_history)\n",
    "        raise ValueError('Error: get_swagger_updates_v2 : There are updates since ' + current_date + 'but shas were not extracted')\n",
    "\n",
    "    if file_dates:\n",
    "        oldest, days_behind = get_oldest_date_v2(file_dates)\n",
    "        changes['oldest_commit'] = oldest.split('T')[0] + ',' + days_behind +' ago'\n",
    "\n",
    "    changes['file_dates'] = file_dates\n",
    "    changes['commit_sha'] = commit_sha\n",
    "    changes['swagger_behind'] = swagger_behind\n",
    "    \n",
    "    #get the pull path. \n",
    "    ##get PR from swagger. \n",
    "    \n",
    "    pr_num = get_pr_from_swagger_path(azure_api_swagger_path)\n",
    "    \n",
    "    changes['pr_num'] = pr_num\n",
    "\n",
    "    #print(changes)\n",
    "\n",
    "    return changes\n",
    "\n",
    "def get_swagger_updates(azure_api_swagger_path, git_url=None, current_sha=None):\n",
    "    \"\"\"\n",
    "    return the updates to a swagger. \n",
    "    if a current_sha of a swagger is known, function returns the updates 'since' this current sha\n",
    "    else, function returns the entire swagger history. \n",
    "    \n",
    "    #current_sha = base_data['current_version']\n",
    "    \n",
    "    \"\"\"\n",
    "    swagger_history = request_helper(git_url+'commits?path=' + azure_api_swagger_path)\n",
    "    \n",
    "    shas, dates , prs = [], [] , []\n",
    "    for s in swagger_history:\n",
    "        shas.append(s['sha'])\n",
    "        dates.append(s['commit']['committer']['date'])\n",
    "        \n",
    "        \n",
    "    #compare the sha. \n",
    "    if current_sha:\n",
    "        try:\n",
    "            sha_index = shas.index(current_sha)\n",
    "            if sha_index > 0: \n",
    "                #i.e. there are more recent shas. \n",
    "                print('new commits discoverd for -> ' + 'index =' + str(sha_index))\n",
    "                print('corresponding_date' + str(dates[sha_index]))\n",
    "\n",
    "                file_dates, commit_sha, swagger_behind = dates[:sha_index], shas[:sha_index] , sha_index\n",
    "                \n",
    "\n",
    "            else:\n",
    "                file_dates, commit_sha, swagger_behind =[],[],0\n",
    "                \n",
    "        except ValueError, Argument:\n",
    "            print \"sha index not found\", Argument\n",
    "            file_dates, commit_sha, swagger_behind = dates, shas, len(shas)\n",
    "            \n",
    "    else:\n",
    "        file_dates, commit_sha, swagger_behind = dates, shas, len(shas)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create an object to return \n",
    "    changes= {}\n",
    "    \n",
    "    if file_dates:\n",
    "        oldest, days_behind = get_oldest_date_v2(file_dates)\n",
    "        changes['oldest_commit'] = oldest.split('T')[0] + ',' + days_behind +' ago'\n",
    "        #print file_dates\n",
    "        #changes['pulls'] = [get_pr_from_commits(c) for c in commit_sha]\n",
    "        \n",
    "    changes['file_dates'] = file_dates\n",
    "    changes['commit_sha'] = commit_sha\n",
    "    changes['swagger_behind'] = swagger_behind\n",
    "    \n",
    "    return changes\n",
    "\n",
    "def get_new_project_names(map_object, git_url=None, ignore_list=None):\n",
    "    \n",
    "    if not ignore_list:\n",
    "        ignore_list = ['.github', '.gitignore', '.travis.yml', '.vscode', 'LICENSE' , 'README.md' , 'azure-rest-api-specs.sln', \n",
    "          'azure-rest-api-specs.njsproj', 'documentation', 'package.json', '.scripts' , 'scripts']\n",
    "        \n",
    "    if not git_url:\n",
    "        git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "        \n",
    "        \n",
    "    api_folders = request_helper(git_url+'contents/')\n",
    "    \n",
    "    new_projects = []\n",
    "    for folder in api_folders:\n",
    "        f = folder['path'] #\n",
    "\n",
    "        if f not in ignore_list: \n",
    "            test =0 \n",
    "            for m in map_object:     \n",
    "                if f in m:\n",
    "                    test =1\n",
    "                    break; \n",
    "\n",
    "            if test ==0:\n",
    "                new_projects.append(f)\n",
    "                #print ('New project added:' + f)\n",
    "    return new_projects\n",
    "\n",
    "def get_new_project_details(new_projects_list, git_url=None):\n",
    "    \n",
    "    if not git_url:\n",
    "        git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "        \n",
    "    \n",
    "    new_output ={}\n",
    "    for p in new_projects_list:\n",
    "        #print (get_key_folder_params(git_url,p))\n",
    "        is_composite, folders, swagger = get_key_folder_params_v2(git_url,p)\n",
    "        if not new_output.get(p):\n",
    "\n",
    "            new_output[p] ={}\n",
    "            new_output[p]['is_composite'] = is_composite\n",
    "            new_output[p]['latest_folder'] = folders[-1]\n",
    "            new_output[p]['swagger'] = swagger\n",
    "            new_output[p]['commits'] = []\n",
    "            new_output[p]['commit_dates'] = []\n",
    "\n",
    "            #get swagger file history\n",
    "            r_files = request_helper(git_url+'commits?path=' + swagger)\n",
    "            for r in r_files:\n",
    "                commit_sha = r['sha']\n",
    "                commit_date = r['commit']['committer']['date']\n",
    "                new_output[p]['commits'].append(commit_sha)\n",
    "                new_output[p]['commit_dates'].append(commit_date)\n",
    "                \n",
    "            #get the oldest commit \n",
    "            \n",
    "            new_output[p]['oldest_commit'] =''\n",
    "            if new_output[p]['commit_dates']:\n",
    "                oldest, days_behind = get_oldest_date_v2(new_output[p]['commit_dates'])\n",
    "                new_output[p]['oldest_commit']= oldest.split('T')[0] + \",\" + days_behind + \" ago \"\n",
    "        \n",
    "                 \n",
    "\n",
    "    #print(new_output)\n",
    "    return(new_output)\n",
    "\n",
    "#print(get_new_project_details(get_new_project_names()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRATCH WORK BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(get_python_sdk_build_info('azure-mgmt-cdn'))\n",
    "with open('config/api2sdk2nuget.json', 'r') as f:\n",
    "    sdk_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_sdk_projects = sorted(sdk_projects)\n",
    "real_sdk = lambda x:'.'.join(x.split('.')[:-1])\n",
    "for i,s in enumerate(sorted_sdk_projects):\n",
    "    if '.20' in s:\n",
    "        real_s = real_sdk(s)\n",
    "        print s, real_sdk\n",
    "        if real_s == real_sdk(sorted_sdk_projects[i+1]):\n",
    "            #remove i \n",
    "            del sorted_sdk_projects[i]\n",
    "\n",
    "sorted_sdk_projects       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sdk = 'azure-graphrbac'\n",
    "get_python_sdk_build_info(test_sdk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json,shutil\n",
    "import requests, jinja2\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\"\n",
    "base_url = \"https://www.nuget.org/packages/\"\n",
    "package = 'Microsoft.Azure.Management.DataLake.Store'\n",
    "page_result = requests.get(base_url + package)\n",
    "\"\"\"\n",
    "#globals (via a config later on)\n",
    "git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "\n",
    "raw_url = 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/' \n",
    "#cfile= request_helper(raw_url + x[-1])\n",
    "\n",
    "#load base files (map and latest build file to compare against. )\n",
    "\n",
    "with open('config/api2sdk2nuget.json', 'r') as f:\n",
    "    map_object = json.load(f)\n",
    "\n",
    "with open('config/fudge.json', 'r') as f:\n",
    "    build_file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_projs = [c for c in build_file['projects'] if build_file['projects'][c].get('swagger_meta')['is_composite'] == 'Yes' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_projs = [u'graphrbac',\n",
    " u'web',\n",
    " u'network',\n",
    " u'monitor.data',\n",
    " u'sql',\n",
    " u'compute',\n",
    " u'monitor.mgmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#update the build so we have the necessary data. \n",
    "for cp in comp_projs:\n",
    "    #get the info \n",
    "    \n",
    "    \"\"\"\n",
    "        'swagger_path_a' : {\n",
    "        \"sha\": [ ],\n",
    "        \"dates\" :[]\n",
    "    },\n",
    "\n",
    "        'swagger_path_b' : {\n",
    "        \"sha\": [ ],\n",
    "        \"dates\" :[]\n",
    "    },\n",
    "\n",
    "}\n",
    "    \"\"\"\n",
    "    #print cp\n",
    "    \n",
    "    d ={}\n",
    "    comp_file = build_file['projects'][cp]['swagger']\n",
    "    azure_api_name = build_file['projects'][cp]['swagger_meta']['azure_api_spec_folder']\n",
    "    #print comp_file\n",
    "    raw_url = 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/' \n",
    "    cfile= request_helper(raw_url + comp_file)\n",
    "    \n",
    "    print cfile\n",
    "    \n",
    "    if cfile.get('documents'):\n",
    "        for f in cfile.get('documents'):\n",
    "            #get file history \n",
    "            ind_swagger = azure_api_name + f[1:]\n",
    "            print ind_swagger\n",
    "            file_data = get_swagger_updates(ind_swagger, git_url, current_sha=None)\n",
    "            d[ind_swagger] = {'sha' : file_data['commit_sha'], 'dates': file_data['file_dates']}\n",
    "            \n",
    "            #print d\n",
    "            \n",
    "            build_file['projects'][cp]['individual_file_history'] = d \n",
    "            \n",
    "\n",
    "with open('config/build002.json', 'w') as f:\n",
    "    json.dump(build_file, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stable = soup.find(\"tr\", class_= \"versionTableRow recommended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recent = soup.findAll(\"tr\", class_= \"versionTableRow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent[0].find(\"span\")['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent[0].find(\"a\", href=True)['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "package = 'Microsoft.Azure.Management.DataLake.Store'\n",
    "get_recent_from_nuget_v2(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#globals (via a config later on)\n",
    "git_url = 'https://api.github.com/repos/Azure/azure-rest-api-specs/'\n",
    "test_comp_folder ='arm-network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_key_folder_params_v3(git_url, test_comp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ('Yes',\n",
    " [u'2015-05-01-preview',\n",
    "  u'2015-06-15',\n",
    "  u'2016-03-30',\n",
    "  u'2016-06-01',\n",
    "  u'2016-09-01',\n",
    "  u'2016-12-01',\n",
    "  u'2017-03-01'],\n",
    " u'arm-network/compositeNetworkClient.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_folders = x[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the swagger file names. \n",
    "#for each file, get the history ..l\n",
    "#compare the history as usual. current_date of individual swagger == current_date of the composite file. \n",
    "raw_url = 'https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/' \n",
    "cfile= request_helper(raw_url + x[-1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfile['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_swagger = 'arm-network' + '/2017-03-01/swagger/applicationGateway.json'\n",
    "get_swagger_updates(test_swagger, git_url, current_sha=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('changes/latest.json') as f:\n",
    "    test = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in test['existing_projects']:\n",
    "    #print t\n",
    "    if test['existing_projects'][t].get('changes'):\n",
    "        print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in sorted(existing_projects.iterkeys()):\n",
    "    print key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
